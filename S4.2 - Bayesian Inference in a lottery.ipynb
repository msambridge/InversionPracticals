{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 4.2: Bayesian Inference applied to a lottery #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "*Andrew Valentine & Malcolm Sambridge - Research School of Earth Sciences, The Australian National University - Last updated Sept. 2019*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--<badge>--><a href=\"https://colab.research.google.com/github/anu-ilab/JupyterPracticals/blob/main/S4.2 - Bayesian Inference in a lottery.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a><!--</badge>-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In this practical, we will compare Bayesian and Frequentist approaches to using published data to estimate the number of tickets sold in a national lottery. The single unknown in the problem is the total number of entries (i.e. sets of 6 numbers) sold, which we will call $n$. The data is the number of\n",
    "winning entries of each division $d_i, (i=1,\\dots,N_{div}) $, where $N_{div}$ is\n",
    "6 for the example below. These are given without error. Of\n",
    "course, since both the cost per entry and the total prize money are\n",
    "published then an estimate of $n$, allows a direct inference on the\n",
    "total profit before costs made by the lotto organisation. (In reality\n",
    "the real value of $n$ is never made public!)\n",
    "\n",
    "We will look at the problem both from a Frequentist viewpoint, using the\n",
    "data to make a single estimate of $n$, and also a Bayesian inference\n",
    "viewpoint where we use the data to construct a probability distribution\n",
    "for $n$.\n",
    "\n",
    "### Background theory\n",
    "\n",
    "The probability of winning each division, is independent of the total\n",
    "number of entries $n$, so these may be treated as a set of known\n",
    "constants, $p_i, (i=1,\\dots, N_{div})$, the value of which depends on\n",
    "the details of the game. \n",
    "\n",
    "<img src=\"../Figures/table.png\" alt=\"Bootstrap figure\" width=\"600\"/>\n",
    "\n",
    "Table 1. $p_i$ is the probability of winning division $i$ and $d_i$ are the number of actual winners in division $i$. Australian Tattslotto dividend results for draw number 3253 on 29/09/2012. Total prize pool of $\\$49.92$m, with division 1 prize of $\\$22$m. The cost of a single entry is about $\\$0.65$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------- #\n",
    "#                                                          #\n",
    "#     Uncomment below to set up environment on \"colab\"     #\n",
    "#                                                          #\n",
    "# -------------------------------------------------------- #\n",
    "\n",
    "# !pip install -U anu-inversion-course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": true,
    "editable": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math as mt\n",
    "ds = [14.,169.,3059.,149721.,369543.,802016.]  # data for the lottery problem\n",
    "pm1s = [8145060.,678756.,36696.,732.,300.,144.] # inverse probabilities for the lottery problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Task 1**  A Frequentist solution might be to take the number of winners of\n",
    "    each division and divide by the probability of winning to get\n",
    "    multiple estimates of $n$. These estimates are independent and we\n",
    "    could average them. Do this for the data above to get an estimate\n",
    "    for $n$. By how much do these estimates vary ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Try it here! You can insert more cells by selecting Cell > Insert Cell Above/Below from the menu\n",
    "# bar, or by pressing Esc to enter command mode and then hitting A or B (for above/below). \n",
    "#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Task 2**  A Bayesian inference approach requires us to find the Likelihood and\n",
    "    prior and then multiply them together. Lets assume our prior is\n",
    "    uniform between $1< n < 3\\times 10^8$ which is a safe assumption.\n",
    "    The likelihood is the probability of the data given the model, i.e.\n",
    "    the probability that there would be $d_i$ winners of division $i$\n",
    "    and $n - d_i$ non winners when there are $n$ tickets sold. The\n",
    "    binomial theorem tells us that this probability, $p(d_i | n)$, is\n",
    "    given by\n",
    "$$p(d_i | n) = \\frac{n!}{d_i! (n-d_i)!} \\times p_i^{d_i} (1-p_i)^{n-d_i}$$\n",
    "\n",
    "All values in this expression are known except the value of\n",
    "    $n$. Since the number of winners in each division provides\n",
    "    independent data, the total likelihood is the product of similar\n",
    "    terms for each division, i.e.   \n",
    "$$p({\\bf d}| n) =\\prod_{i=1}^{N_{div}} p(d_i | n)$$\n",
    "\n",
    "Bayesâ€™ theorem says that to find the <span>*a posteriori*</span>\n",
    "    probability distribution for the unknown $n$ we just multiply the\n",
    "    likelihood by the prior. Since the prior is a constant the result is\n",
    "\n",
    "$$p(n | {\\bf d}) \\propto  \\prod_{i=1}^{N_{div}} \\frac{n!}{(n-d_i)!} \\times (1-p_i)^{n-d_i}\n",
    "       $$\n",
    "\n",
    "where we have dropped terms that do not depend on $n$. This holds for $1 \\le n \\le 3\\times 10^8$. Outside this range the\n",
    "    posterior PDF is zero because the prior is zero. Our only interest\n",
    "    is in the unknown $n$ and so the constant of proportionality is used\n",
    "    to absorb all quantities independent of $n$.\n",
    "\n",
    "Your task is to use the values of $(d_i, p_i), i=1,\\dots, 6$ from\n",
    "    the table and plot the posterior probability distribution as a function of\n",
    "    $n$. Do this in the range 112.5m - 114.5m. Did you get the type of figure that you expected? \n",
    "    Compare this curve to the single frequentist estimate of $n$ you obtained in part 1, what do you\n",
    "    notice?\n",
    "    \n",
    "[Hint: In any computer program it is always best to calculate $\\log p(n | {\\bf d})$ first and then take an exponent to evaluate the curve as a function of $n$. Stirling's formulae for the approximation to $n!$ may be useful.]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Try it here! You can insert more cells by selecting Cell > Insert Cell Above/Below from the menu\n",
    "# bar, or by pressing Esc to enter command mode and then hitting A or B (for above/below). \n",
    "#\n",
    "\n",
    "# Stirlings formual for log(N!), valid for N large\n",
    "def logfac(N):\n",
    "    fN = float(N)\n",
    "    return fN*mt.log(fN) + mt.log(2*mt.pi*fN)/2 - fN + \\\n",
    "      (fN**-1)/12 - (fN**-3)/360 + (fN**-5)/1260 - (fN**-7)/1680 + (fN**-9)/1188\n",
    "\n",
    "def logp(n): # here we evaluate Stirlings formula for log of factorial n\n",
    "    res = 0.\n",
    "    for pm1,d in zip(pm1s,ds):\n",
    "        res += logfac(n) - logfac(n-d)\n",
    "        res += (n-d)*mt.log((pm1-1.)/pm1)\n",
    "    return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Task 3**  \n",
    "Repeat the problem using the Maximum Likelihood (ML) approach. This\n",
    "    is done by finding the value of $n$ which maximises the \n",
    "    likelihood. Since the prior is a\n",
    "    constant for this problem the likelihood is proportional to the\n",
    "    curve you produced in part 2. You could probably do it visually.\n",
    "    Plot the average estimate you obtained in part 1 on top of the curve\n",
    "    from part 2. How does the ML solution compare to the Bayesian solution and the Frequentist solution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Try it here! You can insert more cells by selecting Cell > Insert Cell Above/Below from the menu\n",
    "# bar, or by pressing Esc to enter command mode and then hitting A or B (for above/below). \n",
    "#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
